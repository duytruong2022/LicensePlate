{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0818b01262c65e8964154e4cc5fa06d99d872c2536afdb929f2802138ea159624",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\hai.nv173089\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000186D9F01280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000186DAFE81F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000186D9E30790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000186DB8D2AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000186DC945B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imutils\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "import math\n",
    "from glob import glob\n",
    "from tkinter import filedialog\n",
    "import time\n",
    "import random\n",
    "class ALPR:\n",
    "    def __init__(self, minAR=3, maxAR=5, dataPath='data/'):\n",
    "        self.dataPath=dataPath\n",
    "        self.minAR=minAR\n",
    "        self.maxAR=maxAR\n",
    "    def getAllImagePath(self):\n",
    "        mypath='data'\n",
    "        files = [f for f in listdir(self.dataPath) if isfile(join(self.dataPath, f))]\n",
    "        return files\n",
    "    def removeFolderContent(self,folderpath):\n",
    "        files=glob(folderpath+'/*')\n",
    "        ok=0\n",
    "        if files==None:\n",
    "            files=glob(folderpath+'*')\n",
    "        for f in files:\n",
    "            ok=os.remove(f)\n",
    "        return ok\n",
    "    def imgshow(self, image):\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.show()\n",
    "    def readImage(self, file_name):\n",
    "        return cv2.imread(file_name, 0)\n",
    "    def locate_license_plate_candidates(self, gray, keep=5):       \n",
    "        rectKern = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 5))\n",
    "        blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKern)\n",
    "        squareKern = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        light = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, squareKern)\n",
    "        light = cv2.threshold(light, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        gradX = cv2.Sobel(blackhat, ddepth=cv2.CV_32F,dx=1, dy=0, ksize=-1)\n",
    "        gradX = np.absolute(gradX)\n",
    "        (minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
    "        gradX = 255 * ((gradX - minVal) / (maxVal - minVal))\n",
    "        gradX = gradX.astype(\"uint8\")\n",
    "        gradX = cv2.GaussianBlur(gradX, (5, 5), 0)\n",
    "        gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKern)\n",
    "        thresh = cv2.threshold(gradX, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "        thresh = cv2.bitwise_and(thresh, thresh, mask=light)\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        thresh = cv2.erode(thresh, None, iterations=1)\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:keep]\n",
    "        # print(cnts)\n",
    "        return (blackhat, cnts)\n",
    "    def countObjectArea(self, image):\n",
    "        area=image[image==255].size\n",
    "        return area\n",
    "    def removeSmallComponents(self, image, original_plate):\n",
    "        # find all your connected components (white blobs in your image)\n",
    "        nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8)\n",
    "        # print(image.shape)\n",
    "\n",
    "        sizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "        threshold=sorted(sizes, reverse=True)[8]\n",
    "        # threshold=13\n",
    "        img2 = np.zeros((output.shape),dtype = np.uint8)\n",
    "        componentBorder = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "        self.removeFolderContent('imgs/')\n",
    "        for i in range(0, len(sizes)):\n",
    "            if sizes[i] >= threshold:\n",
    "                \n",
    "                x = stats[i+1, cv2.CC_STAT_LEFT]\n",
    "                y = stats[i+1, cv2.CC_STAT_TOP]\n",
    "                w = stats[i+1, cv2.CC_STAT_WIDTH]\n",
    "                h = stats[i+1, cv2.CC_STAT_HEIGHT]\n",
    "                if h/w >1.2 and h/w <7:\n",
    "                    img2[output == i + 1] = 255\n",
    "                    cv2.rectangle(componentBorder, (x-1, y-1), (x + w+1, y + h+1), (0, 255, 0), 1)\n",
    "                    img_save=original_plate[y:y+h,x:x+w]\n",
    "                    # self.imgshow(img_save)\n",
    "\n",
    "                    cv2.imwrite(\"imgs/\"+str(x)+'_'+str(y)+'.jpg',img_save)\n",
    "        # self.imgshow(componentBorder)\n",
    "        \n",
    "        return img2\n",
    "\n",
    "    def locate_license_plate(self, gray, candidates,blackhat , clearBorder=True):\n",
    "        lpcnt=None\n",
    "        roi=None\n",
    "        for ar_i_min in [3,2.5,2,1]:\n",
    "            for c in candidates:\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                # tính tỷ lệ của chiều dài và chiều rộng\n",
    "                ar = w / float(h)\n",
    "                if ar >= ar_i_min and ar <= 5:\n",
    "                    lpCnt = c\n",
    "                    licensePlate =blackhat[y:y + h, x:x + w]\n",
    "                    original_plate=gray[y:y+h, x:x+w]\n",
    "                    roi=~cv2.threshold(licensePlate, 127, 255,\n",
    "                                cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "                    roi=self.removeSmallComponents(roi, licensePlate)\n",
    "                    bitwise_and = cv2.bitwise_and(roi, licensePlate)\n",
    "                    return ('lpText', bitwise_and, x, y, w, h)\n",
    "    def normalizePredict(self, img):\n",
    "        d=np.abs(img.shape[0]-img.shape[1])//2\n",
    "        extend=np.zeros((img.shape[0], d))\n",
    "        img=np.hstack((extend, img))\n",
    "        img=np.hstack((img,extend))\n",
    "        img=cv2.resize(img, (30,30))\n",
    "        # self.imgshow(img)\n",
    "        img=img.reshape((1,30,30,1)).astype('float32')/255.0\n",
    "        return img\n",
    "    def predict_image(self, filepath=None, img=None):\n",
    "        model1 = load_model('model_number_2.h5')\n",
    "        model=load_model('model_character1.h5')\n",
    "        # label for number\n",
    "        maplabel1={'0':0,'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9}\n",
    "        inv_map1 = {v: k for k, v in maplabel1.items()}\n",
    "        #label for character\n",
    "        maplabel={'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,'N':13,'P':14,'Q':15,'R':16,'S':17,'T':18,'U':19,'V':20,'W':21,'X':22,'Y':23,'Z':24}\n",
    "        inv_map = {v: k for k, v in maplabel.items()}\n",
    "        if img is not None:\n",
    "            gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        elif filepath is not None:\n",
    "            img=cv2.imread(filepath)\n",
    "            gray=cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        # gray=cv2.resize(gray, (470,300))\n",
    "        # self.imgshow(gray)\n",
    "        blackhat, candidates=alpr.locate_license_plate_candidates(gray)\n",
    "        data_result=alpr.locate_license_plate(gray, candidates, blackhat)\n",
    "        if data_result is not None:\n",
    "            data_result[1]\n",
    "        imglistpaths=glob('imgs/*.jpg')\n",
    "        imglistpaths=sorted(imglistpaths, key= lambda s : int(s[5:-4].split('_')[0]))\n",
    "        lptext=''\n",
    "        for i in range(len(imglistpaths)):\n",
    "            img_character = self.normalizePredict(cv2.imread(imglistpaths[i],0))\n",
    "            if i!=2:\n",
    "                \n",
    "                digit = model1.predict_classes(img_character)\n",
    "                lptext=lptext+str(digit[0])\n",
    "            else:\n",
    "                \n",
    "                digit = model.predict_classes(img_character)\n",
    "                lptext=lptext+str(digit[0])\n",
    "        try:\n",
    "            x, y, w, h=data_result[2], data_result[3], data_result[4], data_result[5]\n",
    "        except:\n",
    "            return None\n",
    "        cv2.rectangle(img, (x-1, y-1), (x + w+1, y + h+1), (0, 255, 0), 1)\n",
    "        return (img, lptext, x, y)\n",
    "    \n",
    "    def videoPredict(self):\n",
    "        vid = cv2.VideoCapture('Video3.mp4')\n",
    "        while(True):\n",
    "            ret, frame = vid.read()\n",
    "            if random.randint(0,10)==0:\n",
    "                try:\n",
    "                    (img, lptext, x, y)=self.predict_image(img=frame)\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "            font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            bottomLeftCornerOfText = (x,y)\n",
    "            fontScale              = 1\n",
    "            fontColor              = (0,255,0)\n",
    "            lineType               = 2\n",
    "\n",
    "            cv2.putText(img,lptext, \n",
    "                bottomLeftCornerOfText, \n",
    "                font, \n",
    "                fontScale,\n",
    "                fontColor,\n",
    "                lineType)\n",
    "            cv2.imshow('img', img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        vid.release()\n",
    "        cv2.destroyAllWindows()\n",
    "alpr=ALPR()\n",
    "# filename=filedialog.askopenfilename()\n",
    "# alpr.predict_image(filepath=filename)\n",
    "\n",
    "alpr.videoPredict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}